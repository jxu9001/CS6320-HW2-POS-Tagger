{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB_MuuS5KuR1",
        "outputId": "253bdb82-6539-4070-ecbe-232965e6cfb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# install necessary packages using pip\n",
        "!pip install keras numpy wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.9/dist-packages (2.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.22.4)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.9/dist-packages (3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import set_random_seed\n",
        "set_random_seed(42)"
      ],
      "metadata": {
        "id": "QUTjC07PjmwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f-YNX2OLJlP",
        "outputId": "67c36a44-8c28-4d5d-82b7-59c6a8766c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT37l9LMoGYx"
      },
      "source": [
        "def load_corpus(path):\n",
        "    sentences = []\n",
        "    for file_name in os.listdir(path):\n",
        "        with open(os.path.join(path, file_name), 'r') as f:\n",
        "            for line in f:\n",
        "                if line.strip():\n",
        "                    sentence = []\n",
        "                    for word_tag in line.split():\n",
        "                        word, tag = word_tag.split('/')\n",
        "                        sentence.append((word.lower(), tag))\n",
        "                    sentences.append(sentence)\n",
        "    return sentences\n",
        "\n",
        "# test the function here:\n",
        "path = os.path.join(os.getcwd(), 'drive', 'My Drive', 'cs6320', 'modified_brown') \n",
        "data = load_corpus(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f3c2TtDMJMK",
        "outputId": "df8f7b2b-5425-4f9d-bf49-3c471267059c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('in', 'PREPOSITION'),\n",
              " ('sentences', 'NOUN'),\n",
              " (',', 'PUNCT'),\n",
              " ('patterns', 'NOUN'),\n",
              " ('of', 'PREPOSITION'),\n",
              " ('stress', 'NOUN'),\n",
              " ('are', 'VERB'),\n",
              " ('determined', 'VERB'),\n",
              " ('by', 'PREPOSITION'),\n",
              " ('complex', 'ADJECTIVE'),\n",
              " ('combinations', 'NOUN'),\n",
              " ('of', 'PREPOSITION'),\n",
              " ('influences', 'NOUN'),\n",
              " ('that', 'PRONOUN'),\n",
              " ('can', 'VERB'),\n",
              " ('only', 'ADVERB'),\n",
              " ('be', 'VERB'),\n",
              " ('suggested', 'VERB'),\n",
              " ('here', 'ADVERB'),\n",
              " ('.', 'PUNCT')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFJvfGCPois_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e3075cb-9845-4df3-bbf7-0a7dcaf425d3"
      },
      "source": [
        "import numpy as np # you may need this to convert lists to np arrays before returning them\n",
        "\n",
        "# Creates the dataset with train_X (words) and train_y (tag).\n",
        "def create_dataset(sentences):\n",
        "    word_to_idx = {word: i for i, word in enumerate(sorted({wt[0] for s in sentences for wt in s}), 2)}\n",
        "    word_to_idx['[PAD]'] = 0\n",
        "    word_to_idx['[OOV]'] = 1\n",
        "    tag_to_idx = {tag: i for i, tag in enumerate(sorted({wt[1] for s in sentences for wt in s}), 1)}\n",
        "    tag_to_idx['[PAD]'] = 0\n",
        "    \n",
        "    train_x = []\n",
        "    train_y = []\n",
        "    \n",
        "    for sentence in sentences:\n",
        "        words = []\n",
        "        tags = []\n",
        "        for word, tag in sentence:\n",
        "            words.append(word_to_idx[word])\n",
        "            tags.append(tag_to_idx[tag])\n",
        "        train_x.append(words)\n",
        "        train_y.append(tags)\n",
        "\n",
        "    return train_x, train_y, word_to_idx, tag_to_idx\n",
        "# Test the function here\n",
        "train_x, train_y, word_to_idx, tag_to_idx = create_dataset(data)\n",
        "print(train_x[0], train_y[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[23075, 39676, 393, 32734, 31195, 42784, 4349, 13468, 8023, 10581, 10316, 31195, 23507, 44517, 8284, 31446, 5722, 43196, 21611, 405] [7, 5, 9, 5, 7, 5, 10, 10, 7, 1, 5, 7, 5, 8, 10, 2, 10, 10, 2, 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk0ZTHkvplxD"
      },
      "source": [
        "from keras.utils import pad_sequences as pad\n",
        "# Pad the sequences with 0s to the max length.\n",
        "def pad_sequences(train_x, train_y):\n",
        "    MAX_LENGTH = len(max(train_x, key=len))  # 180\n",
        "    train_x = pad(train_x, maxlen=MAX_LENGTH, padding='post')\n",
        "    train_y = pad(train_y, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "    return train_x, train_y, MAX_LENGTH\n",
        "    \n",
        "\n",
        "# Test the function\n",
        "train_x, train_y, MAX_LENGTH = pad_sequences(train_x, train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G55zdGENWDTe",
        "outputId": "7d530146-2784-4d18-bf7a-767a1b97fd06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7,  5,  9,  5,  7,  5, 10, 10,  7,  1,  5,  7,  5,  8, 10,  2, 10,\n",
              "       10,  2,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edy9gTV6qIhv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d49c5d5c-954b-4810-f494-38fdb2f8dba9"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import InputLayer, Activation\n",
        "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Define the Keras model.\n",
        "def define_model(MAX_LENGTH):  \n",
        "    \n",
        "    # Define 'model' here\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
        "    model.add(Embedding(input_dim=len(word_to_idx), output_dim=128))\n",
        "    model.add(Bidirectional(LSTM(units=256, return_sequences=True)))\n",
        "    model.add(TimeDistributed(Dense(units=len(tag_to_idx))))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=Adam(0.001),\n",
        "                  metrics=['accuracy'])\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "# Call the function here\n",
        "model = define_model(MAX_LENGTH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 180, 128)          6367104   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 180, 512)         788480    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 180, 12)          6156      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " activation (Activation)     (None, 180, 12)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,161,740\n",
            "Trainable params: 7,161,740\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0c2a7eUPQFi"
      },
      "source": [
        "# Returns the one-hot encoding of the sequence.\n",
        "def to_categorical(train_y, num_tags):\n",
        "    cat_sequences = []\n",
        "    for s in train_y:\n",
        "        cats = []\n",
        "        for item in s:\n",
        "            cats.append(np.zeros(num_tags))\n",
        "            cats[-1][item] = 1.0\n",
        "        cat_sequences.append(cats)\n",
        "    return np.array(cat_sequences)\n",
        "# Call the function as to_categorical(train_y, categories = len(tag2idx))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN-Roc_AORIp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac03ef57-45ed-4eb9-aafb-db9bcfdf63aa"
      },
      "source": [
        "import tensorflow as tf\n",
        "# Trains the model.\n",
        "def train(model, train_x, train_y):\n",
        "    # Fit the data into the Keras model, through 40 passes (epochs) using model.fit()\n",
        "    model.fit(train_x, to_categorical(train_y, len(tag_to_idx)), batch_size=128, epochs=40, validation_split=0.2)\n",
        "    # Return the model.\n",
        "    return model\n",
        "\n",
        "# call function here\n",
        "model = train(model, train_x, train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "365/365 [==============================] - 12s 22ms/step - loss: 0.1894 - accuracy: 0.9443 - val_loss: 0.0277 - val_accuracy: 0.9922\n",
            "Epoch 2/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.0125 - val_accuracy: 0.9959\n",
            "Epoch 3/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.0112 - val_accuracy: 0.9963\n",
            "Epoch 4/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0107 - val_accuracy: 0.9965\n",
            "Epoch 5/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0110 - val_accuracy: 0.9966\n",
            "Epoch 6/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0112 - val_accuracy: 0.9965\n",
            "Epoch 7/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0118 - val_accuracy: 0.9965\n",
            "Epoch 8/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0135 - val_accuracy: 0.9962\n",
            "Epoch 9/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0128 - val_accuracy: 0.9964\n",
            "Epoch 10/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0136 - val_accuracy: 0.9965\n",
            "Epoch 11/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0144 - val_accuracy: 0.9964\n",
            "Epoch 12/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0155 - val_accuracy: 0.9962\n",
            "Epoch 13/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 9.6692e-04 - accuracy: 0.9997 - val_loss: 0.0164 - val_accuracy: 0.9963\n",
            "Epoch 14/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 7.5577e-04 - accuracy: 0.9998 - val_loss: 0.0174 - val_accuracy: 0.9963\n",
            "Epoch 15/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 5.9526e-04 - accuracy: 0.9998 - val_loss: 0.0187 - val_accuracy: 0.9961\n",
            "Epoch 16/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 4.9972e-04 - accuracy: 0.9999 - val_loss: 0.0195 - val_accuracy: 0.9961\n",
            "Epoch 17/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 3.9062e-04 - accuracy: 0.9999 - val_loss: 0.0210 - val_accuracy: 0.9960\n",
            "Epoch 18/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 3.3202e-04 - accuracy: 0.9999 - val_loss: 0.0209 - val_accuracy: 0.9961\n",
            "Epoch 19/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 3.1328e-04 - accuracy: 0.9999 - val_loss: 0.0218 - val_accuracy: 0.9961\n",
            "Epoch 20/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 2.9867e-04 - accuracy: 0.9999 - val_loss: 0.0226 - val_accuracy: 0.9960\n",
            "Epoch 21/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 2.0722e-04 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9961\n",
            "Epoch 22/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 1.5968e-04 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9959\n",
            "Epoch 23/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 1.2977e-04 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9960\n",
            "Epoch 24/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 1.1810e-04 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 0.9960\n",
            "Epoch 25/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 1.5130e-04 - accuracy: 1.0000 - val_loss: 0.0265 - val_accuracy: 0.9959\n",
            "Epoch 26/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 2.0673e-04 - accuracy: 0.9999 - val_loss: 0.0267 - val_accuracy: 0.9959\n",
            "Epoch 27/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 2.6498e-04 - accuracy: 0.9999 - val_loss: 0.0266 - val_accuracy: 0.9959\n",
            "Epoch 28/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 1.4188e-04 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 0.9960\n",
            "Epoch 29/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 6.8950e-05 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9960\n",
            "Epoch 30/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 3.6743e-05 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 0.9960\n",
            "Epoch 31/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 2.4826e-05 - accuracy: 1.0000 - val_loss: 0.0283 - val_accuracy: 0.9960\n",
            "Epoch 32/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 2.0281e-05 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.9960\n",
            "Epoch 33/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 2.2451e-05 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 0.9960\n",
            "Epoch 34/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 2.6373e-05 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.9960\n",
            "Epoch 35/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 3.6829e-04 - accuracy: 0.9999 - val_loss: 0.0286 - val_accuracy: 0.9959\n",
            "Epoch 36/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 2.3719e-04 - accuracy: 0.9999 - val_loss: 0.0283 - val_accuracy: 0.9960\n",
            "Epoch 37/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 8.8885e-05 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 0.9960\n",
            "Epoch 38/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 3.6608e-05 - accuracy: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.9961\n",
            "Epoch 39/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 1.5651e-05 - accuracy: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.9961\n",
            "Epoch 40/40\n",
            "365/365 [==============================] - 7s 20ms/step - loss: 1.2763e-05 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.9961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANPb-K98i0w8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ab55648-30a5-40e8-94c5-3b279c679e12"
      },
      "source": [
        "# Test a sentence using the given model.\n",
        "def test(model, sentence):\n",
        "    processed_sentence = np.zeros(MAX_LENGTH, dtype='int')\n",
        "    idx_to_tag = {i: tag for tag, i in tag_to_idx.items()}\n",
        "    for i, word in enumerate(sentence.split()):\n",
        "        processed_sentence[i] = (word_to_idx.get(word, word_to_idx['[OOV]']))\n",
        "    processed_sentence = np.expand_dims(processed_sentence, axis=0)\n",
        "    prediction = model.predict(processed_sentence).squeeze()\n",
        "    prediction = [np.argmax(tag) for tag in prediction if np.argmax(tag) != 0]\n",
        "    return [idx_to_tag[tag] for tag in prediction]\n",
        "\n",
        "\n",
        "s1 = 'the planet jupiter and its moons are in effect a mini solar system .'\n",
        "s2 = 'computers process programs accurately .'\n",
        "print('The most likely tag sequence for the sentence \\\"{}\\\" is:\\n {}'.format(s1, test(model, s1)))\n",
        "print('The most likely tag sequence for the sentence \\\"{}\\\" is:\\n {}'.format(s2, test(model, s2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 700ms/step\n",
            "The most likely tag sequence for the sentence \"the planet jupiter and its moons are in effect a mini solar system .\" is:\n",
            " ['DETERMINER', 'NOUN', 'NOUN', 'CONJUNCTION', 'PRONOUN', 'NOUN', 'VERB', 'PREPOSITION', 'VERB', 'DETERMINER', 'ADJECTIVE', 'ADJECTIVE', 'NOUN', 'PUNCT']\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "The most likely tag sequence for the sentence \"computers process programs accurately .\" is:\n",
            " ['NOUN', 'NOUN', 'NOUN', 'ADVERB', 'PUNCT']\n"
          ]
        }
      ]
    }
  ]
}